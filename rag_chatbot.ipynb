{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG chatbot \n",
    "Version 1.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_classic.retrievers import MultiQueryRetriever\n",
    "import chromadb\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress ChromaDB telemetry warnings as they are useless as ChromaDB trying to send usage data but failing because it can't find its own version information\n",
    "import logging\n",
    "logging.getLogger(\"chromadb\").setLevel(logging.ERROR)\n",
    "\n",
    "# Jupyter-specific imports\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Set environment variable for protobuf\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF loaded successfully: TaskFlow.pdf\n"
     ]
    }
   ],
   "source": [
    "# Load PDF\n",
    "doc_path = \"TaskFlow.pdf\"\n",
    "if doc_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=doc_path, languages=[\"deu\"])\n",
    "    data = loader.load()\n",
    "    print(f\"PDF loaded successfully: {doc_path}\")\n",
    "else:\n",
    "    print(\"Upload documents\")\n",
    "\n",
    "#TODO: language detection!!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT TEXT INTO CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 6\n"
     ]
    }
   ],
   "source": [
    "#Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "print(f\"Number of text chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE VECTOR DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create vector database\n",
    "client = chromadb.PersistentClient(path=\"./chroma_data\")\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "    collection_name=\"rag_chatbot_collection\",\n",
    "    client=client\n",
    ")\n",
    "print(\"Vector database created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up LLM and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up LLM and retrieval\n",
    "local_model = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_model, temperature=0.1)\n",
    "\n",
    "# Query prompt template\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are a query rephrasing assistant for a vector database search.\n",
    "    Your task is to generate **3** alternative, semantically diverse versions of the user's question. These variations should explore different terminology, structures, or angles of the original query to maximize relevant document retrieval.\n",
    "    Provide only the rephrased questions, with each one separated by a newline. Do not include any introductory phrases, explanations, or the original question itself.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "# Set up retriever\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt template\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# Create chain (pipeline)\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat with PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_pdf(question):\n",
    "    \"\"\"\n",
    "    Chat with the PDF using the RAG chain.\n",
    "    \"\"\"\n",
    "    return display(Markdown(chain.invoke(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The main idea of this document appears to be a specification or requirements document for a task management system, outlining the functional and non-functional requirements for its development and implementation. The document covers various aspects such as user interface, data storage, API functionality, performance, and usability, among others."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1\n",
    "chat_with_pdf(\"What is the main idea of this document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The two options for technical implementation of this system are:\n",
       "\n",
       "1. Implementierung als Webanwendung (Spring o.Ã¤.)\n",
       "2. Implementierung als Desktop Anwendung (Swing)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2\n",
    "chat_with_pdf(\"What are the two options for technical implementation of this system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided context, it seems that you are working with a TaskFlow system, which is a task management system for employees in companies. The document provides requirements and specifications for the system.\n",
       "\n",
       "To answer your question, \"What should I do?\", I'll provide some general steps based on the context:\n",
       "\n",
       "1. **Review the requirements**: Carefully read through the document's page content to understand the functional, performance, security, and maintainability requirements of the TaskFlow system.\n",
       "2. **Identify areas for improvement**: Based on your understanding of the requirements, identify areas where you can improve or optimize the system, such as performance bottlenecks or security vulnerabilities.\n",
       "3. **Develop a plan**: Create a plan to address the identified areas, including any necessary changes to the code, data storage, or API implementation.\n",
       "4. **Implement changes**: Start implementing the planned changes, following the modular architecture and testing guidelines outlined in the document.\n",
       "5. **Test and validate**: Thoroughly test the updated system to ensure it meets the requirements and performs well under various scenarios.\n",
       "6. **Monitor and maintain**: Continuously monitor the system's performance and security, making adjustments as needed to maintain the required availability and reliability.\n",
       "\n",
       "Please note that these steps are general suggestions based on the provided context and may not be specific to your exact situation. If you have more information or clarification about your project, I'd be happy to provide more tailored advice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 4\n",
    "chat_with_pdf(\"What should I do? Can you give me some steps?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rag (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
