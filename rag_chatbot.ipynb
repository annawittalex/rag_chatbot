{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG chatbot \n",
    "Version 1.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_classic.retrievers import MultiQueryRetriever\n",
    "import chromadb\n",
    "\n",
    "# For formatting output\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Set environment variable for protobuf to prevent potential \n",
    "# protobuf-related errors when running the RAG chatbot with LangChain and Ollama\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF loaded successfully: TaskFlow.pdf\n"
     ]
    }
   ],
   "source": [
    "# Load PDF\n",
    "doc_path = \"TaskFlow.pdf\"\n",
    "if doc_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=doc_path, languages=[\"deu\"])\n",
    "    data = loader.load()\n",
    "    print(f\"PDF loaded successfully: {doc_path}\")\n",
    "else:\n",
    "    print(\"Upload documents\")\n",
    "\n",
    "#TODO: language detection!!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT TEXT INTO CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 6\n"
     ]
    }
   ],
   "source": [
    "#Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(data) \n",
    "print(f\"Number of text chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE VECTOR DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create vector database\n",
    "client = chromadb.PersistentClient(path=\"./chroma_data\") \n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "    collection_name=\"rag_chatbot_collection\",\n",
    "    client=client\n",
    ")\n",
    "print(\"Vector database created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up LLM and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up LLM and retrieval\n",
    "local_model = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_model, temperature=0.1)\n",
    "\n",
    "# Query prompt template\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are a query rephrasing assistant for a vector database search.\n",
    "    Your task is to generate **3** alternative, semantically diverse versions of the user's question. These variations should explore different terminology, structures, or angles of the original query to maximize relevant document retrieval.\n",
    "    Provide only the rephrased questions, with each one separated by a newline. Do not include any introductory phrases, explanations, or the original question itself.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "# Set up retriever\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt template\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template) \n",
    "\n",
    "\n",
    "# Create chain (pipeline): context from retriever + unchanged question + prompt + llm + output parser as string\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat with PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_pdf(question):\n",
    "    \"\"\"\n",
    "    Chat with the PDF using the RAG chain.\n",
    "    \"\"\"\n",
    "    return display(Markdown(chain.invoke(question)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The main idea of this document appears to be a technical specification for a task management system, outlining requirements and guidelines for its implementation, functionality, and performance. The document covers various aspects such as user interface, data storage, API design, testing, and non-functional requirements like usability and performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1\n",
    "chat_with_pdf(\"What is the main idea of this document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Die beiden Optionen für die technische Implementierung des Systems sind:\n",
       "\n",
       "1. Implementierung als Webanwendung (Spring oder ähnliche Frameworks)\n",
       "2. Implementierung als Desktop-Anwendung (Swing)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2\n",
    "chat_with_pdf(\"What are the two options for technical implementation of this system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided context from the TaskFlow.pdf document, it appears that you are tasked with managing personal tasks using a task management system called TaskFlow.\n",
       "\n",
       "Here are some steps you can follow:\n",
       "\n",
       "1. **Create a new task**: Go to the \"Aufgabenverwaltung\" section and click on the \"Neue Aufgabe erstellen\" button. Fill in the required fields, including title, description, priority, and optional deadline.\n",
       "2. **Edit an existing task**: Locate the task you want to edit and click on the \"Bearbeiten\"-button. Update the relevant fields, such as title, description, or priority, and save the changes.\n",
       "3. **Delete a task**: Find the task you want to delete and click on the \"Löschen\"-button. Confirm that you want to delete the task by clicking on the \"Ja\" button after being prompted for confirmation.\n",
       "4. **View all tasks**: Go to the \"Aufgabenansicht\" section and view the list of all tasks, sorted by priority and then by deadline.\n",
       "5. **Filter tasks**: Use the filter options to narrow down the list of tasks based on status, priority, deadline, or search criteria in title or description.\n",
       "6. **View task details**: Click on a task to view its detailed information, including history of status changes.\n",
       "7. **Check statistics**: Go to the \"Statistikübersicht\" section to view statistics on the number of tasks per status and overdue tasks.\n",
       "\n",
       "Please note that these steps are based solely on the provided context and may not be an exhaustive list of all possible actions or features available in TaskFlow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 4\n",
    "chat_with_pdf(\"What should I do? Can you give me some steps?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rag (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
